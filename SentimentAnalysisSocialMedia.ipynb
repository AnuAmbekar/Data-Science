{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sentiment.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for column in df.text:\n",
    "    corpus.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = []\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            no_stopwords.append(token)\n",
    "            \n",
    "            \n",
    "    return no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[upset, update, Facebook, texting, cry, result,  , School, today, Blah]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\anurag\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anurag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "df['preprocessed'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset can't update Facebook texting it... migh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>@Kenichan I dived many times ball. Managed sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>@nationwideclass no, behaving all. i'm mad. he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>@Kwesidei whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1467836500</td>\n",
       "      <td>Mon Apr 06 22:26:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>natalieantipas</td>\n",
       "      <td>so rylee,grace...wana go steve's party or not?...</td>\n",
       "      <td>rylee,grace...wana go steve's party not?? SADL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1467836576</td>\n",
       "      <td>Mon Apr 06 22:26:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>timdonnelly</td>\n",
       "      <td>hey, I actually won one of my bracket pools! T...</td>\n",
       "      <td>hey, I actually one bracket pools! Too bad one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1467836583</td>\n",
       "      <td>Mon Apr 06 22:26:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>homeworld</td>\n",
       "      <td>@stark YOU don't follow me, either  and i work...</td>\n",
       "      <td>@stark YOU follow me, either work you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1467836859</td>\n",
       "      <td>Mon Apr 06 22:26:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>willy_chaz</td>\n",
       "      <td>A bad nite for the favorite teams: Astros and ...</td>\n",
       "      <td>A bad nite favorite teams: Astros Spartans los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1467836873</td>\n",
       "      <td>Mon Apr 06 22:26:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LeakySpoon</td>\n",
       "      <td>Body Of Missing Northern Calif. Girl Found: P...</td>\n",
       "      <td>Body Of Missing Northern Calif. Girl Found: Po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                     timestamp      flag            user  \\\n",
       "0   1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1   1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2   1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3   1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4   1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "..         ...                           ...       ...             ...   \n",
       "95  1467836500  Mon Apr 06 22:26:28 PDT 2009  NO_QUERY  natalieantipas   \n",
       "96  1467836576  Mon Apr 06 22:26:29 PDT 2009  NO_QUERY     timdonnelly   \n",
       "97  1467836583  Mon Apr 06 22:26:29 PDT 2009  NO_QUERY       homeworld   \n",
       "98  1467836859  Mon Apr 06 22:26:33 PDT 2009  NO_QUERY      willy_chaz   \n",
       "99  1467836873  Mon Apr 06 22:26:33 PDT 2009  NO_QUERY      LeakySpoon   \n",
       "\n",
       "                                                 text  \\\n",
       "0   is upset that he can't update his Facebook by ...   \n",
       "1   @Kenichan I dived many times for the ball. Man...   \n",
       "2     my whole body feels itchy and like its on fire    \n",
       "3   @nationwideclass no, it's not behaving at all....   \n",
       "4                       @Kwesidei not the whole crew    \n",
       "..                                                ...   \n",
       "95  so rylee,grace...wana go steve's party or not?...   \n",
       "96  hey, I actually won one of my bracket pools! T...   \n",
       "97  @stark YOU don't follow me, either  and i work...   \n",
       "98  A bad nite for the favorite teams: Astros and ...   \n",
       "99   Body Of Missing Northern Calif. Girl Found: P...   \n",
       "\n",
       "                                         preprocessed  \n",
       "0   upset can't update Facebook texting it... migh...  \n",
       "1   @Kenichan I dived many times ball. Managed sav...  \n",
       "2                    whole body feels itchy like fire  \n",
       "3   @nationwideclass no, behaving all. i'm mad. he...  \n",
       "4                                @Kwesidei whole crew  \n",
       "..                                                ...  \n",
       "95  rylee,grace...wana go steve's party not?? SADL...  \n",
       "96  hey, I actually one bracket pools! Too bad one...  \n",
       "97             @stark YOU follow me, either work you!  \n",
       "98  A bad nite favorite teams: Astros Spartans los...  \n",
       "99  Body Of Missing Northern Calif. Girl Found: Po...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wednesday b-day! know 2 do!!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"preprocessed\"][90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "\n",
    "\n",
    "train_x = [\"upset can't update Facebook texting it might cry result School today also Blah\",\n",
    "          \"I dived many times ball. Managed save 50% The rest go bounds\",\n",
    "          \"whole body feels itchy like fire\",\n",
    "          \"no, behaving all. i'm mad. here? I can't see there.\",\n",
    "          \n",
    "          \"hey long time see! Yes.. Rains bit ,only bit LOL , I'm fine thanks , how's\",\n",
    "          \"ahh ive always wanted see rent love soundtrack\",\n",
    "          \"awe love too\",\n",
    "          \"Yay I'm happy job\",\n",
    "          \n",
    "          \"ill tell ya story later good day ill workin like three hours\",\n",
    "          \"Bed. Class 8-12. Work 12-3. Gym 3-5 6. Then class 6-10. Another day that's gonna fly by\",\n",
    "          \"really feel like getting today got study tomorrows practical exam\",\n",
    "          \"Gym attire today was: Puma singlet, Adidas shorts and black business socks leather shoes\"]\n",
    "\n",
    "train_y = [Sentiment.NEGATIVE, Sentiment.NEGATIVE, Sentiment.NEGATIVE, Sentiment.NEGATIVE, \n",
    "           Sentiment.POSITIVE, Sentiment.POSITIVE, Sentiment.POSITIVE, Sentiment.POSITIVE,\n",
    "           Sentiment.NEUTRAL, Sentiment.NEUTRAL, Sentiment.NEUTRAL, Sentiment.NEUTRAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "docs = [nlp(text) for text in train_x]\n",
    "train_x_vectors = [doc.vector for doc in docs]\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "test_x = [\"I'm upset\"]\n",
    "docs = [nlp(text) for text in test_x]\n",
    "test_x_vectors = [doc.vector for doc in docs]\n",
    "\n",
    "clf_svm.predict(test_x_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "#print(train_x)\n",
    "docs = [nlp(text) for text in train_x]\n",
    "train_x_word_vectors = [x.vector for x in docs]\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm_wv = svm.SVC(kernel='linear')\n",
    "clf_svm_wv.fit(train_x_word_vectors, train_y)\n",
    "\n",
    "test_x = [\"This restaurant is not bad\", \"This restaurant is rubbish\"]\n",
    "test_docs = [nlp(text) for text in test_x]\n",
    "test_x_word_vectors =  [x.vector for x in test_docs]\n",
    "\n",
    "clf_svm_wv.predict(test_x_word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
